{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Do_an_HK202.ipynb",
      "provenance": [],
      "mount_file_id": "1SL4LVgZcgOShhK8h2ZWxpJUrlOpBh19I",
      "authorship_tag": "ABX9TyO/eSAGTZegBFcUAqoQQ8e8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Minatozaki0911/CapstoneProject202/blob/main/Do_an_HK202.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyUppdDltxu7",
        "outputId": "37dfa616-b12b-45de-803d-3f6780047779"
      },
      "source": [
        "!pip install keras"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.4.3)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras) (1.19.5)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras) (1.5.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBZmTthCe3Gb"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.style as style\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import models, layers, optimizers\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing import image as image_utils\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from PIL import Image\n",
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "import pandas as pd"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5x8cyX3kvTNc",
        "outputId": "3776bde0-5a22-4b18-a07f-9fe60acf00b9"
      },
      "source": [
        "!unzip '/content/drive/MyDrive/Colab Notebooks/DO_AN_HK202/dataHandLang.zip' -d '/content/drive/mMyDrive/Colab Notebooks/DO_AN_HK202/train'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/MyDrive/Colab Notebooks/DO_AN_HK202/dataHandLang.zip\n",
            "checkdir:  cannot create extraction directory: /content/drive/mMyDrive/Colab Notebooks/DO_AN_HK202/train\n",
            "           No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUS161ji0QvQ"
      },
      "source": [
        "gesture_names = {0: 'E',\n",
        "                 1: 'L',\n",
        "                 2: 'F',\n",
        "                 3: 'V',\n",
        "                 4: 'B'}\n",
        "\n",
        "gestures = {'L_': 'L',\n",
        "           'fi': 'E',\n",
        "           'ok': 'F',\n",
        "           'pe': 'V',\n",
        "           'pa': 'B'\n",
        "            }\n",
        "\n",
        "gestures_map = {'E': 0,\n",
        "                'L': 1,\n",
        "                'F': 2,\n",
        "                'V': 3,\n",
        "                'B': 4\n",
        "                }\n",
        "dimension = 224            "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eO0UABnz1me"
      },
      "source": [
        "image_path = '/content/drive/MyDrive/Colab Notebooks/DO_AN_HK202/train'\n",
        "model_path = '/content/drive/MyDrive/Colab Notebooks/DO_AN_HK202/'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxeKbQtM16fu"
      },
      "source": [
        "def process_image(path):\n",
        "    img = Image.open(path)\n",
        "    img = img.resize((dimension, dimension))\n",
        "    img = np.array(img)\n",
        "    return img"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0S74aAd18b9"
      },
      "source": [
        "def process_data(X_data, y_data):\n",
        "    X_data = np.array(X_data, dtype = 'float32')\n",
        "    X_data = np.stack((X_data,)*3, axis=-1)\n",
        "    X_data /= 255\n",
        "    y_data = np.array(y_data)\n",
        "    y_data = to_categorical(y_data)\n",
        "    return X_data, y_data"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdaqutPk19s3"
      },
      "source": [
        "def walk_file_tree(image_path):\n",
        "    X_data = []\n",
        "    y_data = []\n",
        "    for directory, subdirectories, files in os.walk(image_path):\n",
        "        for file in files:\n",
        "            if not file.startswith('.'):\n",
        "                path = os.path.join(directory, file)\n",
        "                gesture_name = gestures[file[0:2]]\n",
        "                print(gesture_name)\n",
        "                print(gestures_map[gesture_name])\n",
        "                y_data.append(gestures_map[gesture_name])\n",
        "                X_data.append(process_image(path))\n",
        "\n",
        "            else:\n",
        "                continue\n",
        "\n",
        "    X_data, y_data = process_data(X_data, y_data)\n",
        "    return X_data, y_data"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTz9dq662BPO"
      },
      "source": [
        "X_data, y_data = walk_file_tree(image_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4uHN3dP238U"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data,\n",
        "                                                    test_size = 0.2, \n",
        "                                                    random_state=12, \n",
        "                                                    stratify=y_data)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsUXaQh328uz"
      },
      "source": [
        "model_checkpoint = ModelCheckpoint(filepath=model_path, save_best_only=True)\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy',\n",
        "                               min_delta=0,\n",
        "                               patience=10,\n",
        "                               verbose=1,\n",
        "                               mode='auto',\n",
        "                               restore_best_weights=True)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qe6Xodhy3JDd"
      },
      "source": [
        "model1 = VGG16(weights='imagenet', include_top=False, input_shape=(dimension, dimension, 3))\n",
        "optimizer1 = optimizers.Adam()\n",
        "base_model = model1"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYp0RNJh3Sel"
      },
      "source": [
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "predictions = Dense(5, activation='softmax')(x)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVVbTvXL4hmN"
      },
      "source": [
        "model = Model(inputs=base_model.input, outputs=predictions)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "211avZkl479o"
      },
      "source": [
        "for layer in base_model.layers:\n",
        "    layer.trainable = False"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCQPswNE5C9l"
      },
      "source": [
        "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vk9A_UZj5LG9",
        "outputId": "ee19843b-6a28-491e-d747-7ebdaeaf41cc"
      },
      "source": [
        "model.fit(X_train, y_train, epochs=7, batch_size=64, validation_data=(X_test, y_test), verbose=1,\n",
        "          callbacks=[early_stopping, model_checkpoint])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/7\n",
            "35/35 [==============================] - 775s 22s/step - loss: 0.7383 - accuracy: 0.7147 - val_loss: 0.1118 - val_accuracy: 0.9673\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/DO_AN_HK202/assets\n",
            "Epoch 2/7\n",
            "35/35 [==============================] - 773s 22s/step - loss: 0.0821 - accuracy: 0.9745 - val_loss: 0.0463 - val_accuracy: 0.9855\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/DO_AN_HK202/assets\n",
            "Epoch 3/7\n",
            "35/35 [==============================] - 775s 22s/step - loss: 0.0290 - accuracy: 0.9900 - val_loss: 0.0753 - val_accuracy: 0.9782\n",
            "Epoch 4/7\n",
            "35/35 [==============================] - 773s 22s/step - loss: 0.0201 - accuracy: 0.9936 - val_loss: 0.1026 - val_accuracy: 0.9709\n",
            "Epoch 5/7\n",
            "35/35 [==============================] - 772s 22s/step - loss: 0.0243 - accuracy: 0.9927 - val_loss: 0.0465 - val_accuracy: 0.9891\n",
            "Epoch 6/7\n",
            "35/35 [==============================] - 772s 22s/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.0549 - val_accuracy: 0.9891\n",
            "Epoch 7/7\n",
            "35/35 [==============================] - 772s 22s/step - loss: 8.1604e-04 - accuracy: 1.0000 - val_loss: 0.0549 - val_accuracy: 0.9909\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe52548e110>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsL08GIus_Ep"
      },
      "source": [
        "model.save('ThaiBaoKhangModel.h5')"
      ],
      "execution_count": 18,
      "outputs": []
    }
  ]
}